{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 1: GeForce GTX TITAN X (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "np.random.seed(1004)\n",
    "import click\n",
    "import gc\n",
    "import os\n",
    "from data_multiscale import *\n",
    "from util import *\n",
    "import time\n",
    "from unet_model_multiscale import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "\n",
    "rep_finetune = 100\n",
    "patience = 10\n",
    "time_stamp = 6\n",
    "num_iter = 600\n",
    "\n",
    "def scheduler(epoch):\n",
    "    return lr*(0.99 ** epoch)\n",
    "\n",
    "def scheduler_fine(epoch):\n",
    "    return lr*(0.99 ** epoch)/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 1474616802\n",
      "row_size: 24, channel_size: 4\n",
      "num_patch: 400, proportion: 0.5\n",
      "learning rate: 0.0005, batch_size: 16\n",
      "model number: 1, Epochs: 150\n",
      "net_size: 24, repeat: 2\n"
     ]
    }
   ],
   "source": [
    "row_size, channel_size = 24, 4\n",
    "num_patch, proportion = 400, 0.5\n",
    "learning, batch_size = 5e-4, 16\n",
    "model_num, nb_epoch = 1, 150\n",
    "net_size, rep = 24, 2\n",
    "gpu = 1\n",
    "\n",
    "global lr\n",
    "lr = learning\n",
    "start = str(int(time.time()))\n",
    "\n",
    "print(\"start: {}\".format(start))\n",
    "print(\"row_size: {}, channel_size: {}\".format(row_size, channel_size))\n",
    "print(\"num_patch: {}, proportion: {}\".format(num_patch, proportion))\n",
    "print(\"learning rate: {}, batch_size: {}\".format(learning, batch_size))\n",
    "print(\"model number: {}, Epochs: {}\".format(model_num, nb_epoch))\n",
    "print(\"net_size: {}, repeat: {}\".format(net_size, rep))     \n",
    "\n",
    "GT_class, nfolds = np.load('../input/classLabel_5_folds.npy'), 5\n",
    "kf = StratifiedKFold(GT_class, n_folds=nfolds, shuffle=True, random_state=1004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiscale Res U-net with dropout!!!!!!!!!!!!!!!!\n",
      "Train 1-Fold\n",
      "Test classes : [0, 2, 5, 1, 3, 4]\n",
      "Load Validation\n",
      "START POOLING: VALIDATION\n",
      "DONE POOLING: VALIDATION\n",
      "Creating and compiling model...\n",
      "NUMBER OF PARAMETERS: 363217\n",
      "Finetuning model......\n",
      "START POOLING: VALIDATION\n",
      "DONE POOLING: VALIDATION\n",
      "NUMBER OF LAYERS: 141\n",
      "Epoch 1/100\n",
      "9600/9600 [==============================] - 132s - loss: -0.2508 - dice_coef: 0.2509 - val_loss: -0.3210 - val_dice_coef: 0.3211\n",
      "Epoch 2/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2544 - dice_coef: 0.2545 - val_loss: -0.3232 - val_dice_coef: 0.3232\n",
      "Epoch 3/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2465 - dice_coef: 0.2466 - val_loss: -0.3232 - val_dice_coef: 0.3233\n",
      "Epoch 4/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2594 - dice_coef: 0.2594 - val_loss: -0.3209 - val_dice_coef: 0.3210\n",
      "Epoch 5/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2497 - dice_coef: 0.2498 - val_loss: -0.3215 - val_dice_coef: 0.3216\n",
      "Epoch 6/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2554 - dice_coef: 0.2555 - val_loss: -0.3276 - val_dice_coef: 0.3277\n",
      "Epoch 7/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2536 - dice_coef: 0.2537 - val_loss: -0.3231 - val_dice_coef: 0.3231\n",
      "Epoch 8/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2597 - dice_coef: 0.2598 - val_loss: -0.3216 - val_dice_coef: 0.3217\n",
      "Epoch 9/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2428 - dice_coef: 0.2429 - val_loss: -0.3206 - val_dice_coef: 0.3207\n",
      "Epoch 10/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2610 - dice_coef: 0.2611 - val_loss: -0.3201 - val_dice_coef: 0.3202\n",
      "Epoch 11/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2331 - dice_coef: 0.2331 - val_loss: -0.3263 - val_dice_coef: 0.3264\n",
      "Epoch 12/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2315 - dice_coef: 0.2316 - val_loss: -0.3192 - val_dice_coef: 0.3193\n",
      "Epoch 13/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2393 - dice_coef: 0.2393 - val_loss: -0.3232 - val_dice_coef: 0.3233\n",
      "Epoch 14/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2359 - dice_coef: 0.2360 - val_loss: -0.3243 - val_dice_coef: 0.3243\n",
      "Epoch 15/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2347 - dice_coef: 0.2347 - val_loss: -0.3165 - val_dice_coef: 0.3165\n",
      "Epoch 16/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2332 - dice_coef: 0.2333 - val_loss: -0.3185 - val_dice_coef: 0.3186\n",
      "Epoch 17/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2335 - dice_coef: 0.2336 - val_loss: -0.3160 - val_dice_coef: 0.3161\n",
      "Validating model...\n",
      "data:1, GT: 0.000301249543129, pred: 0.0055724026864\n",
      "[[0, 0], [0, 0], [78, 0], [457, 0], [654, 0], [102, 0], [0, 0], [0, 0], [0, 0], [0, 0], [540, 111], [933, 100], [915, 0], [200, 0], [24, 0], [0, 0], [0, 0], [0, 0], [0, 0]]\n",
      "Dice Coef: 0.0884783665532\n",
      "data:2, GT: 0.00150624767412, pred: 0.00846639711257\n",
      "[[0, 0.0], [51, 0.0], [332, 0.0], [618, 0.0], [559, 0.0], [585, 0.0], [906, 144.0], [895, 254.0], [699, 287.0], [496, 246.0], [278, 124.0], [44, 0.0], [132, 0.0], [198, 0.0], [107, 0.0], [30, 0.0], [0, 0.0], [0, 0.0], [0, 0.0]]\n",
      "Dice Coef: 0.292054402291\n",
      "data:3, GT: 0.0305361385234, pred: 0.022034048337\n",
      "[[0, 0], [0, 0], [0, 0], [53, 250], [477, 545], [1013, 1337], [1629, 1847], [1877, 2069], [1969, 2135], [1993, 2202], [1997, 2185], [1880, 2262], [1380, 2412], [829, 2164], [305, 1304], [31, 657], [0, 19], [0, 0], [0, 0]]\n",
      "Dice Coef: 0.746041661009\n",
      "data:4, GT: 0.000807444254557, pred: 0.0146465301514\n",
      "[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [59, 0], [995, 0], [1596, 0], [1792, 0], [2053, 0], [3355, 102], [3709, 189], [3855, 389], [2832, 447], [1535, 143], [1154, 0], [102, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]\n",
      "Dice Coef: 0.104496647056\n",
      "data:5, GT: 0.00590960184733, pred: 0.0147393544515\n",
      "[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [474, 0], [1299, 0], [1598, 344], [2434, 471], [3097, 1269], [3888, 1264], [4176, 1294], [3331, 1049], [1924, 1301], [962, 1192], [0, 1111], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]\n",
      "Dice Coef: 0.176242379457\n",
      "data:6, GT: 0.00739417717471, pred: 0.0242655793129\n",
      "[[0, 0], [0, 0], [0, 0], [0, 0], [192, 0], [859, 96], [1196, 184], [1634, 556], [1993, 696], [2393, 965], [2590, 1275], [2332, 1041], [1858, 333], [1000, 33], [678, 0], [267, 0], [4, 0], [0, 0], [0, 0]]\n",
      "Dice Coef: 0.430033821871\n",
      "NUMBER OF PARAMETERS: 122737\n",
      "Train 2-Fold\n",
      "Test classes : [1, 4, 2, 3, 5, 0]\n",
      "Load Validation\n",
      "START POOLING: VALIDATION\n",
      "DONE POOLING: VALIDATION\n",
      "Creating and compiling model...\n",
      "NUMBER OF PARAMETERS: 122737\n",
      "Finetuning model......\n",
      "START POOLING: VALIDATION\n",
      "DONE POOLING: VALIDATION\n",
      "NUMBER OF LAYERS: 141\n",
      "Epoch 1/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2698 - dice_coef: 0.2699 - val_loss: -0.3584 - val_dice_coef: 0.3585\n",
      "Epoch 2/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2698 - dice_coef: 0.2699 - val_loss: -0.3580 - val_dice_coef: 0.3582\n",
      "Epoch 3/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2626 - dice_coef: 0.2626 - val_loss: -0.3582 - val_dice_coef: 0.3583\n",
      "Epoch 4/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2720 - dice_coef: 0.2721 - val_loss: -0.3593 - val_dice_coef: 0.3594\n",
      "Epoch 5/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2497 - dice_coef: 0.2498 - val_loss: -0.3599 - val_dice_coef: 0.3601\n",
      "Epoch 6/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2618 - dice_coef: 0.2618 - val_loss: -0.3606 - val_dice_coef: 0.3608\n",
      "Epoch 7/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2672 - dice_coef: 0.2673 - val_loss: -0.3591 - val_dice_coef: 0.3592\n",
      "Epoch 8/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2552 - dice_coef: 0.2552 - val_loss: -0.3585 - val_dice_coef: 0.3587\n",
      "Epoch 9/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2641 - dice_coef: 0.2642 - val_loss: -0.3622 - val_dice_coef: 0.3623\n",
      "Epoch 10/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2607 - dice_coef: 0.2607 - val_loss: -0.3609 - val_dice_coef: 0.3611\n",
      "Epoch 11/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2457 - dice_coef: 0.2458 - val_loss: -0.3642 - val_dice_coef: 0.3643\n",
      "Epoch 12/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2642 - dice_coef: 0.2643 - val_loss: -0.3621 - val_dice_coef: 0.3623\n",
      "Epoch 13/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2440 - dice_coef: 0.2441 - val_loss: -0.3623 - val_dice_coef: 0.3624\n",
      "Epoch 14/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2394 - dice_coef: 0.2394 - val_loss: -0.3600 - val_dice_coef: 0.3602\n",
      "Epoch 15/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2355 - dice_coef: 0.2356 - val_loss: -0.3618 - val_dice_coef: 0.3619\n",
      "Epoch 16/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2539 - dice_coef: 0.2540 - val_loss: -0.3605 - val_dice_coef: 0.3607\n",
      "Epoch 17/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2533 - dice_coef: 0.2534 - val_loss: -0.3572 - val_dice_coef: 0.3573\n",
      "Epoch 18/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2481 - dice_coef: 0.2482 - val_loss: -0.3608 - val_dice_coef: 0.3609\n",
      "Epoch 19/100\n",
      "9600/9600 [==============================] - 133s - loss: -0.2382 - dice_coef: 0.2383 - val_loss: -0.3614 - val_dice_coef: 0.3616\n",
      "Epoch 20/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2465 - dice_coef: 0.2466 - val_loss: -0.3598 - val_dice_coef: 0.3600\n",
      "Epoch 21/100\n",
      "9600/9600 [==============================] - 130s - loss: -0.2237 - dice_coef: 0.2238 - val_loss: -0.3630 - val_dice_coef: 0.3631\n",
      "Epoch 22/100\n",
      "9600/9600 [==============================] - 131s - loss: -0.2469 - dice_coef: 0.2470 - val_loss: -0.3605 - val_dice_coef: 0.3606\n",
      "Validating model...\n",
      "data:1, GT: 0.000819512975146, pred: 0.00136490314327\n",
      "[[49, 0], [32, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [72, 0], [127, 83], [130, 84], [146, 84], [360, 116], [33, 124], [0, 83], [6, 0], [1, 0], [0, 0], [0, 0], [0, 0]]\n",
      "Dice Coef: 0.180392156863\n",
      "data:2, GT: 0.010316212972, pred: 0.00970904032389\n",
      "[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 28], [153, 442], [805, 1850], [1492, 2561], [2397, 2630], [2682, 2735], [3232, 2756], [2646, 2158], [1423, 1005], [441, 61], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]\n",
      "Dice Coef: 0.633584150872\n",
      "data:3, GT: 0.00176111857096, pred: 0.00577799479167\n",
      "[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [3, 0], [0, 0], [16, 383], [25, 480], [258, 0], [1202, 262], [1200, 424], [1397, 380], [1716, 433], [1725, 344], [1160, 64], [386, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]\n",
      "Dice Coef: 0.297183336144\n",
      "data:4, GT: 0.00460792824074, pred: 0.00760362413194\n",
      "[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [60, 0], [114, 25], [311, 107], [496, 165], [624, 380], [686, 475], [1123, 580], [1226, 529], [1361, 591], [1183, 667], [884, 537], [293, 516], [37, 361], [0, 147], [11, 16], [0, 0], [0, 0], [0, 0], [0, 0]]\n",
      "Dice Coef: 0.442354683451\n",
      "data:5, GT: 0.0310386970029, pred: 0.0312143069262\n",
      "[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [354, 135], [853, 470], [1455, 641], [1992, 1359], [2369, 2010], [2717, 2033], [2792, 2262], [2417, 2317], [1879, 2236], [1401, 2146], [1360, 2124], [1198, 2187], [913, 1245], [163, 575]]\n",
      "Dice Coef: 0.761140288512\n",
      "data:6, GT: 0.000285466512044, pred: 0.00458780924479\n",
      "[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [14, 0], [476, 0], [1089, 0], [1557, 0], [1440, 0], [917, 102], [660, 116], [597, 175], [418, 56], [48, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0]]\n",
      "Dice Coef: 0.106718851924\n",
      "NUMBER OF PARAMETERS: 122737\n",
      "Train 3-Fold\n",
      "Test classes : [0, 5, 2, 1, 4, 3]\n",
      "Load Validation\n",
      "START POOLING: VALIDATION\n",
      "DONE POOLING: VALIDATION\n",
      "Creating and compiling model...\n",
      "NUMBER OF PARAMETERS: 122737\n",
      "Finetuning model......\n",
      "START POOLING: VALIDATION\n",
      "DONE POOLING: VALIDATION\n",
      "NUMBER OF LAYERS: 141\n",
      "Epoch 1/100\n",
      "1712/9600 [====>.........................] - ETA: 103s - loss: -0.2283 - dice_coef: 0.2283"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "result =[]\n",
    "model = get_unet_multiscale_resu_original(channel_size, row_size, row_size, model_num, n=net_size, lr=learning, repeat=rep)\n",
    "\n",
    "for tr_list, te_list in kf:\n",
    "    count += 1\n",
    "    print(\"Train {}-Fold\".format(count))\n",
    "    print(\"Test classes : {}\".format([GT_class[te] for te in te_list]))\n",
    "    print(\"Load Validation\")\n",
    "    X_val, X_val_tr, y_val, GT_list_val = make_test_data_multiscale((te_list), row_size_=row_size,\\\n",
    "     channel_size_=channel_size, num_patch_=num_patch,   isVal_=True)\n",
    "    X_val, X_val_tr, y_val = preprocess(X=X_val, X_tr=X_val_tr, y=y_val,\\\n",
    "     mean = 0.0, std = 1.0, mean_tr= 0.0, std_tr= 1.0)\n",
    "\n",
    "    #     print('GT train/val:{}/{}'.format(np.mean(GT_list_train),np.mean(GT_list_val)))\n",
    "    \n",
    "    print('Creating and compiling model...')\n",
    "\n",
    "    info_check_string = './weights/model_g_{}_m_{}_p_{}_pro_{}_r_{}_n_{}_re_{}_f_{}.hdf5'.format(gpu, model_num, num_patch, proportion, row_size, net_size, rep, count)\n",
    "    info_check_string_fine = './weights/fine_g_{}_m_{}_p_{}_pro_{}_r_{}_n_{}_re_{}_f_{}.hdf5'.format(gpu, model_num, num_patch, proportion, row_size, net_size, rep, count)\n",
    "    print(\"NUMBER OF PARAMETERS: {}\".format(model.count_params()))\n",
    "\n",
    "    print('Finetuning model......')\n",
    "    X_train, X_train_tr, y_train, GT_list_train = make_test_data_multiscale((tr_list), row_size_=row_size,\\\n",
    "     channel_size_=channel_size, num_patch_=num_patch, isVal_=True)\n",
    "    X_train, X_train_tr, y_train = preprocess(X=X_train, X_tr=X_train_tr, y=y_train,\\\n",
    "     mean = 0.0, std = 1.0, mean_tr= 0.0, std_tr= 1.0)\n",
    "\n",
    "    N_layer = len(model.layers)\n",
    "    freeze_layer = 64 + 10*rep # -18    \n",
    "    print('NUMBER OF LAYERS: {}'.format(N_layer))\n",
    "    for ind, l in enumerate(model.layers):\n",
    "        if ind <= freeze_layer:\n",
    "            l.trainable = False\n",
    "\n",
    "    early_stopping_fine = EarlyStopping(monitor='val_loss', patience=patience)\n",
    "    model_checkpoint_fine = ModelCheckpoint(info_check_string_fine, monitor='loss', save_best_only=True)\n",
    "    change_lr_fine = LearningRateScheduler(scheduler_fine)\n",
    "    model.load_weights(info_check_string)\n",
    "\n",
    "    #     print('GT train/val:{}/{}'.format(np.mean(GT_list_train),np.mean(GT_list_val)))\n",
    "    b_generator_fine = balance_generator(X1 = X_train, X2 = X_train_tr, \\\n",
    "        y = y_train, GT = GT_list_train, batch_size=batch_size)\n",
    "    model.fit_generator(b_generator_fine, samples_per_epoch = (batch_size*num_iter), nb_epoch = rep_finetune, \\\n",
    "     validation_data=({'main_input':X_val, 'scaled_input': X_val_tr},\\\n",
    "      y_val), callbacks=[early_stopping_fine, model_checkpoint_fine, change_lr_fine], nb_worker=2)\n",
    "    \n",
    "    print('Validating model...')\n",
    "    model.load_weights(info_check_string_fine)\n",
    "    stride = 2\n",
    "    _, label_list = make_data_list((te_list), isTrainOrVal = True, isFix = False)\n",
    "    X_val_patch, X_val_patch_tr, cache = make_test_data_multiscale((te_list), \\\n",
    "        row_size_=row_size, channel_size_=channel_size, isVal_ = False, \\\n",
    "        patch_w_stride_ = row_size/stride, patch_c_stride_ = channel_size/2, isFix=True)\n",
    "    N_val = len(X_val_patch)\n",
    "\n",
    "    for i in xrange(N_val):\n",
    "        compare_list = []\n",
    "        X_val_patch_i = np.transpose( X_val_patch[i].reshape(time_stamp, -1, \\\n",
    "            channel_size, row_size, row_size), (1,0,2,3,4) )\n",
    "        X_val_patch_tr_i = np.transpose( X_val_patch_tr[i].reshape(time_stamp, -1, \\\n",
    "            channel_size, row_size, row_size), (1,0,2,3,4) )\n",
    "        X_val_patch_i, X_val_patch_tr_i = preprocess(X=X_val_patch_i, \\\n",
    "            X_tr=X_val_patch_tr_i, y=None,  mean = 0.0, std = 1.0, mean_tr= 0.0, std_tr= 1.0)\n",
    "\n",
    "        y_val_patch_pred_i = model.predict({'main_input':X_val_patch_i, 'scaled_input': X_val_patch_tr_i}, \\\n",
    "            batch_size=batch_size)\n",
    "\n",
    "        y_val_patch_pred = make_brain_multiscale(y_val_patch_pred_i, cache[i], patch_w_stride = row_size/stride, \\\n",
    "            patch_c_stride = channel_size/2)\n",
    "\n",
    "        y_val_patch_pred /= ((stride ** 2) * 2.0)\n",
    "\n",
    "        GT_Y = np.transpose(np.array(label_list[i]), (2,0,1))\n",
    "        zoomRate = [float(ai)/bi for ai, bi in zip(GT_Y.shape, y_val_patch_pred.shape)]\n",
    "        y_val_patch_pred = transform_sol(y_val_patch_pred, zoomRate)\n",
    "        y_val_patch_pred = (y_val_patch_pred >= 0.5)\n",
    "\n",
    "        print('data:{}, GT: {}, pred: {}'.format( (i+1), np.mean(GT_Y), np.mean(y_val_patch_pred)))\n",
    "        for j in xrange(y_val_patch_pred.shape[0]):\n",
    "            compare_list.append([np.sum(y_val_patch_pred[j]), np.sum(GT_Y[j])])\n",
    "        print(compare_list)\n",
    "\n",
    "        dice_coef= cal_dice_coef( y_val_patch_pred.reshape(-1), GT_Y.reshape(-1))            \n",
    "        print('Dice Coef: {}'.format(dice_coef))\n",
    "\n",
    "        result.append(dice_coef)\n",
    "\n",
    "    print(\"NUMBER OF PARAMETERS: {}\".format(model.count_params()))\n",
    "    del X_train, X_train_tr, y_train\n",
    "    del X_val, X_val_tr, y_val\n",
    "    del X_val_patch_i, X_val_patch_tr_i, X_val_patch, X_val_patch_tr\n",
    "    del y_val_patch_pred, y_val_patch_pred_i\n",
    "    gc.collect()\n",
    "\n",
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Finetune records\n",
    "\n",
    "Original model : 363k\n",
    "\n",
    "- 0.426 for 1/15 lr + with 18 + 122k\n",
    "\n",
    "\n",
    "- 0.?? for 1/10 lr + with 18 + 122k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune records (~09/22)\n",
    "\n",
    "Original model : 266k\n",
    "\n",
    "- 0.378 for 1.0 lr + without -18 + finetune : 73k\n",
    "- 0.423 for 0.1 lr + with 18 + finetuen: 92k\n",
    "- do not know but feel bad for 0.2 lr + with 18 + finetuen: 92k\n",
    "- for 0.05 lr + with 18 + finetuen: 92k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
